{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the notebook.\n",
    "\n",
    "# Import the importlib module for reloading modules\n",
    "import importlib\n",
    "\n",
    "# Import the helper functions from the exercise_0_helper_functions module\n",
    "import helper_functions_copy\n",
    "\n",
    "# Reload the exercise_0_helper_functions module to ensure we have the latest version\n",
    "importlib.reload(helper_functions_copy)\n",
    "\n",
    "# Import all functions from the reloaded exercise_0_helper_functions module\n",
    "from helper_functions_copy import *\n",
    "\n",
    "# Dictionary mapping feature names to their descriptions\n",
    "feature_descriptions = {\n",
    "    'mean_radius': \"Average distance from the center to the outer edge of the tumor.\",\n",
    "    'mean_texture': \"How rough or smooth the surface of the tumor feels, on average.\",\n",
    "    'mean_perimeter': \"The average length of the outline of the tumor.\",\n",
    "    'mean_area': \"The average size of the surface of the tumor measured in square units.\",\n",
    "    'mean_smoothness': \"How smooth or bumpy the tumor surface feels, averaged over several observations.\",\n",
    "    'mean_compactness': \"A measure of how tightly the tumor cells are packed together, averaged over several observations.\",\n",
    "    'mean_concavity': \"Average number of indentations or hollow areas on the tumor's surface.\",\n",
    "    'mean_concave_points': \"Average number of sharp dips or points found along the contour of the tumor.\",\n",
    "    'mean_symmetry': \"How evenly shaped the tumor is. A perfectly symmetrical tumor looks the same on both sides.\",\n",
    "    'mean_fractal_dimension': \"A measure that describes the complexity of the tumor shape, showing how jagged the border is on average.\",\n",
    "    'radius_error': \"The change in the tumor's radius across different measurements, indicating how much the size of the tumor varies.\",\n",
    "    'texture_error': \"The change in the tumor's texture across different measurements, showing how much the roughness or smoothness varies.\",\n",
    "    'perimeter_error': \"The change in the outline length of the tumor across different measurements, showing how much the outline varies.\",\n",
    "    'area_error': \"The change in the surface size of the tumor across different measurements, showing how much the area varies.\",\n",
    "    'smoothness_error': \"The change in how smooth or bumpy the tumor surface feels across different measurements.\",\n",
    "    'compactness_error': \"The change in how tightly the tumor cells are packed together across different measurements.\",\n",
    "    'concavity_error': \"The change in the number of indentations or hollow areas on the tumor's surface across different measurements.\",\n",
    "    'concave_points_error': \"The change in the number of sharp dips or points found along the contour of the tumor across different measurements.\",\n",
    "    'symmetry_error': \"The change in how evenly shaped the tumor is across different measurements.\",\n",
    "    'fractal_dimension_error': \"The change in the complexity of the tumor shape across different measurements, showing how much the jaggedness of the border varies.\",\n",
    "    'worst_radius': \"The largest distance from the center to the outer edge of the tumor observed among all measurements.\",\n",
    "    'worst_texture': \"The roughest texture observed on the surface of the tumor.\",\n",
    "    'worst_perimeter': \"The longest outline of the tumor measured among all observations.\",\n",
    "    'worst_area': \"The largest surface area of the tumor measured among all observations.\",\n",
    "    'worst_smoothness': \"The least smooth texture observed on the tumor's surface, indicating the roughest feel.\",\n",
    "    'worst_compactness': \"The highest degree of how tightly the tumor cells are packed together, observed among all measurements.\",\n",
    "    'worst_concavity': \"The deepest indentations observed on the tumor's surface.\",\n",
    "    'worst_concave_points': \"The highest number of sharp dips or points observed along the contour of the tumor.\",\n",
    "    'worst_symmetry': \"The most uneven shape observed in the tumor, where one side differs the most from the other.\",\n",
    "    'worst_fractal_dimension': \"The highest complexity of the tumor shape observed, showing the most jagged border among all measurements.\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Title: Exploring a Dataset with Regression\n",
    "\n",
    "## Introduction\n",
    "Welcome to Exercise 1! In this notebook, we will go through the importance of applying statistical concepts to our data problems and how to get meaningful answers to our questions using the power of programming. This module will help you understand many things about your data.\n",
    "\n",
    "In the world of statistics, we use a tool called **regression** to help us answer such questions. Regression is a method used to find how one thing (like temperature) can predict another thing (like ice cream sales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some made-up data\n",
    "np.random.seed(0)\n",
    "temperatures = np.random.uniform(60, 100, 500)  # Randomly choose temperatures between 60 and 100 degrees\n",
    "ice_cream_sales = temperatures * 1.5 + np.random.normal(0, 10, 500)  # Randomly (kinda) choose sales made\n",
    "\n",
    "# Reshape the temperatures for sklearn\n",
    "temperatures_reshaped = temperatures.reshape(-1, 1)\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(temperatures_reshaped, ice_cream_sales)\n",
    "predictions = model.predict(temperatures_reshaped)\n",
    "\n",
    "# Plot the graph\n",
    "scatter_plot(\n",
    "    X={'data': [temperatures, ice_cream_sales], 'color': 'blue', 'label': 'Ice Cream Sales'}, \n",
    "    line_plot={'x': temperatures, 'y': predictions, 'color': 'red', 'linestyle': '--'},\n",
    "    title='Temperature vs Ice Cream Sales',\n",
    "    show_legend=True,\n",
    "    xlabel='Temperature (Â°F)',\n",
    "    ylabel='Ice Cream Sales'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use regression to classify things, like determining if a student will pass or fail an exam based on their study hours and sleep hours. If you look at the graph below, you can see that the blue line separates the data points. If you fall on the left side of the line, there is a good chance you will fail, and if you land on the right side of the line, there is a good chance you will pass!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data: Hours studied, hours of sleep, and pass/fail outcomes\n",
    "np.random.seed(42)\n",
    "hours_studied = np.random.uniform(1, 10, 500)\n",
    "hours_sleep = np.random.uniform(4, 10, 500)\n",
    "pass_fail = (hours_studied + hours_sleep > 12).astype(int)\n",
    "\n",
    "# Fit the regression model\n",
    "study_sleep_data = np.column_stack((hours_studied, hours_sleep))\n",
    "model = LogisticRegression()\n",
    "model.fit(study_sleep_data, pass_fail)\n",
    "\n",
    "# Line Plot Coordinates\n",
    "x_values = np.linspace(0, 12, 300)\n",
    "y_values = -(model.intercept_ + model.coef_[0][0] * x_values) / model.coef_[0][1]\n",
    "\n",
    "# Defining benign data and malignant data\n",
    "benign_data = [hours_studied[pass_fail == 0], hours_sleep[pass_fail == 0], \"Fail\"]\n",
    "malignant_data = [hours_studied[pass_fail == 1], hours_sleep[pass_fail == 1], \"Pass\"]\n",
    "\n",
    "# Plot the graph\n",
    "scatter_plot(\n",
    "    X={'data': [benign_data[0], benign_data[1]], 'color': 'red', 'label': 'Fail'}, \n",
    "    y={'data': [malignant_data[0], malignant_data[1]], 'color': 'green', 'label': 'Pass'}, \n",
    "    line_plot={'x': x_values, 'y': y_values, 'color': 'blue', 'linestyle': '--'},\n",
    "    title='Logistic Regression: Decision Boundary', \n",
    "    show_legend=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being able to find patterns in your data and learning from it is powerful. Yes, ice cream sales and exam results may be low stakes, but regression can be used in more critical environments.\n",
    "\n",
    "Imagine you have a big source of cancer data at your disposal. You want to see if there is a pattern among them to better aid future patients. This is a big deal, as it allows you to better take care of patients and essentially buy more time by intervening sooner.\n",
    "\n",
    "Wouldn't it be nice to answer some key questions? For example, how big does a tumor have to be, to be considered cancerous? How smooth or rough must the texture be for it to be cancerous? \n",
    "\n",
    "In this exercise, we will go through breast cancer data to answer our questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Loading the Dataset\n",
    "In this notebook, we will explore the Breast Cancer dataset, use a Regression method to classify data, and evaluate the model's performance. \n",
    "\n",
    "First, we load the Breast Cancer dataset using the `load_breast_cancer()` function from the scikit-learn library. This dataset is a well-known collection of breast cancer data that includes various measurements and features related to tumor characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Breast Cancer dataset\n",
    "breast_cancer = load_breast_cancer()\n",
    "X = breast_cancer.data\n",
    "y = breast_cancer.target\n",
    "\n",
    "# Convert the dataset into a DataFrame for visualization\n",
    "df = pd.DataFrame(data=np.c_[X, y], columns=np.append(breast_cancer.feature_names, 'target'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is loaded into variables `X` for the measurements and `y` for the target labels (cancerous or not cancerous). For easier visualization and manipulation, we convert the dataset into a Pandas DataFrame, combining the measurements and target labels into one structured table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Exploring the Dataset\n",
    "Next, let's take a quick look at the dataset to understand its structure and contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the data\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in the table you created represents an individual sample (or patient) from the breast cancer dataset. The columns correspond to various features measured or calculated for that sample, except for the last column labeled âtarget,â which indicates the classification of the sample (0 indicates a benign tumor, which is not cancerous, and 1 indicates a malignant tumor, which is cancerous.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the summary statistics of the dataset\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of target classes\n",
    "sns.countplot(x='target', data=df)\n",
    "plt.title('Distribution of Target Classes')\n",
    "plt.xlabel('Target')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(ticks=[0, 1], labels=breast_cancer.target_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Breast Cancer dataset includes a large number of measurements related to tumor characteristics, making it challenging to visualize all of them at once. \n",
    "\n",
    "To simplify our task and create a clear visualization, we decided to use the first two columns in the dataset: _\"average radius\"_ and _\"average texture\"_. This choice is made for convenience, allowing us to quickly build and visualize our model. Focusing on just these two measurements makes the visualization clearer and more interpretable while still providing meaningful insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So with that in mind lets draw a scatter plot of our data to see things better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot(\n",
    "    X={'data': [X[:, 0], X[:, 1]], 'color': 'blue', 'label': \"mean_radius\"}, \n",
    "    title=\"mean_texture vs mean_radius\", \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the benign and malignant labels to color each data point, we can see how average radius and average texture (or mean radius and mean texture) affect (or don't affect) the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the color-coded data points (with colors indicating benign and malignant tumors)\n",
    "\n",
    "feature1_index = np.argwhere(breast_cancer.feature_names == \"mean radius\").flatten()[0]\n",
    "feature2_index = np.argwhere(breast_cancer.feature_names == \"mean texture\").flatten()[0]\n",
    "\n",
    "# Defining benign data and malignant data\n",
    "benign_data = [X[y == 0][:, feature1_index], X[y == 0][:, feature2_index], \"Benign\"]\n",
    "malignant_data = [X[y == 1][:, feature1_index], X[y == 1][:, feature2_index], \"Malignant\"]\n",
    "\n",
    "# Plot the graph\n",
    "scatter_plot(\n",
    "    X={'data': [benign_data[0], benign_data[1]], 'color': 'green', 'label': 'Benign'}, \n",
    "    y={'data': [malignant_data[0], malignant_data[1]], 'color': 'red', 'label': 'Malignant'}, \n",
    "    title=\"mean texture vs mean radius\", \n",
    "    show_legend=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can see our data visually, we notice that there may be a way to classify the benign and malignant cases based on mean radius and mean texture. As humans, we can visually observe potential patterns in the data points. To formalize this observation, we will use regression as a tool to help us classify these cases. The next step is to split the dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Splitting the Dataset\n",
    "Now, we will split the dataset into **training** and **testing** sets for model training and evaluation. This is important because it allows us to train the model on one part of the data and test it on another part to see how well it performs on new data. This helps us understand the model's ability to make accurate predictions on data it hasn't seen before. We will learn more about this process and its significance later on in the module.\n",
    "\n",
    "In our example today, we will use 80% of the data for training and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # random_state=42 ensures the split is reproducible, meaning the data is split the same way each time the code is run\n",
    "    \n",
    "    print(\"Dataset split was successful\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Building and Training a Classification Model\n",
    "Next, we will build and train a regression model for breast cancer classification. Specifically, we will use a **logistic regression** model that classifies the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Initialize the logistic regression model\n",
    "    model = LogisticRegression(max_iter=10000)  # Try up to 10,000 times to find the best fit\n",
    "\n",
    "    # Select specific variables (mean radius and mean texture) for training\n",
    "    X_train_selected = X_train[:, [0, 1]]  # Columns 0 and 1 correspond to mean radius and mean texture\n",
    "\n",
    "    # Train the model on the selected variables of the training data\n",
    "    model.fit(X_train_selected, y_train)\n",
    "    \n",
    "    print(\"Model training was successful\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if everything went well, we should have successfully initialized and trained our logistic regression model using the selected variables (mean radius and mean texture). The model has learned from the training data and is now ready to make predictions. In the next step, we will evaluate the performance of our model to see how well it can classify new data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluating the Model\n",
    "Now, let's evaluate the performance of the trained model on the testing data.\n",
    "\n",
    "We will use the `model.predict` method to make predictions on the testing data. This method takes the testing data as input and outputs the predicted classifications for each data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Make a prediction\n",
    "    y_pred = model.predict(X_train_selected)\n",
    "    \n",
    "    print(\"Prediction made successfully, results are in y_pred\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will evaluate it using something called a **confusion matrix**. A confusion matrix allows us to see how well our model is performing by comparing the predicted classifications to the actual classifications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "\n",
    "# Plot the heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', cbar=False, xticklabels=breast_cancer.target_names, yticklabels=breast_cancer.target_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also calculate its **accuracy** and generate a **classification report**.\n",
    "\n",
    "First, we calculate the accuracy of the model using the `accuracy_score` function. This function compares the true labels (`y_train`) with the predicted labels (`y_pred`) and returns the percentage of correct predictions. The accuracy score provides a simple metric to understand how often the model makes correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate model Accuracy\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we generate a classification report using the `print_classification_report` function. This report provides a more detailed evaluation of the model, including precision, recall, and F1-score for each class. These metrics help us understand the performance of the model beyond just accuracy, giving insight into how well the model identifies each class. You donât need to know the details of these metrics right now, but itâs good to be aware of them. They may come in handy down the road, so consider reading more about them when you have time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a classification report\n",
    "the_report = classification_report(y_train, y_pred, target_names=breast_cancer.target_names)\n",
    "print(the_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Visualizing the Decision Boundary\n",
    "\n",
    "Now that we see the accuracy is satisfactory, we will take the next step to visualize our model on the graph. By plotting the decision boundary of the logistic regression model, we can better understand how the model classifies the data points and observe the separation between benign and malignant cases. This visualization will help us **see** the effectiveness of our model in distinguishing between the two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line Plot Coordinates\n",
    "x_values = np.linspace(X[:, feature1_index].min(), X[:, feature1_index].max(), 100)\n",
    "y_values = -(model.intercept_ + model.coef_[0][0] * x_values) / model.coef_[0][1]  # Decision boundary equation\n",
    "\n",
    "# Plot the graph\n",
    "scatter_plot(\n",
    "    X={'data': [benign_data[0], benign_data[1]], 'color': 'green', 'label': 'Benign'}, \n",
    "    y={'data': [malignant_data[0], malignant_data[1]], 'color': 'red', 'label': 'Malignant'}, \n",
    "    line_plot={'x': x_values, 'y': y_values, 'color': 'blue', 'linestyle': '--'},\n",
    "    title=\"mean texture vs mean radius\", \n",
    "    show_legend=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see why the accuracy wasn't 100% by looking at the graph. The data points are not perfectly separable by a linear line, indicating that there is some overlap between the benign and malignant cases. This overlap means that a simple linear model will never be able to achieve 100% accuracy with this dataset. The complexity and nature of the data make it challenging for a linear boundary to perfectly classify all instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we repeat all of the steps above **using different columns**? The following Python cell will randomly select two columns and run logistic regression on them to classify the data. Each time you run the cell, it will select different columns for the classification, and you will observe that the accuracy changes accordingly. This is because different variables have varying degrees of correlation with the target variable, impacting the model's performance.\n",
    "\n",
    "run the cell below many times..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running all of it again, but this time with different columns\n",
    "\n",
    "# Randomly select two features to visualize\n",
    "feature_indices = random.sample(range(X.shape[1]), 2)\n",
    "feature1_index = feature_indices[0]\n",
    "feature2_index = feature_indices[1]\n",
    "\n",
    "# Extract the feature base names correctly\n",
    "feature1_base = breast_cancer.feature_names[feature1_index].replace(' ', '_').lower()\n",
    "feature2_base = breast_cancer.feature_names[feature2_index].replace(' ', '_').lower()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train[:, feature_indices], y_train)  # Fit model only on selected features\n",
    "\n",
    "# Line Plot Coordinates\n",
    "x_values = np.linspace(X_test[:, feature1_index].min(), X_test[:, feature1_index].max(), 100)\n",
    "y_values = -(model.intercept_ + model.coef_[0][0] * x_values) / model.coef_[0][1]\n",
    "\n",
    "# Predict on the test set using the same features\n",
    "y_pred = model.predict(X_test[:, feature_indices])\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on test set:\", accuracy)\n",
    "\n",
    "# Plot the graph\n",
    "scatter_plot(\n",
    "    X={'data': [X_test[y_test == 0][:, feature1_index], X_test[y_test == 0][:, feature2_index]], 'color': 'green', 'label': breast_cancer.target_names[0]}, \n",
    "    y={'data': [X_test[y_test == 1][:, feature1_index], X_test[y_test == 1][:, feature2_index]], 'color': 'red', 'label': breast_cancer.target_names[1]},\n",
    "    line_plot={'x': x_values, 'y': y_values, 'color': 'blue', 'linestyle': '--'},\n",
    "    title=f'{breast_cancer.feature_names[feature2_index]} vs {breast_cancer.feature_names[feature1_index]}', \n",
    "    show_legend=True,\n",
    "    xlabel=breast_cancer.feature_names[feature1_index],\n",
    "    ylabel=breast_cancer.feature_names[feature2_index]\n",
    ")\n",
    "# Print statements to describe the plotted graph and its components\n",
    "print(f\"The graph plots \\\"{breast_cancer.feature_names[feature1_index]}\\\" on the x-axis and \\\"{breast_cancer.feature_names[feature2_index]}\\\" on the y-axis.\\n\"\n",
    "    f\"\\t\\\"{breast_cancer.feature_names[feature1_index]}\\\": {feature_descriptions[feature1_base]} (x-axis)\\n\"\n",
    "    f\"\\t\\\"{breast_cancer.feature_names[feature2_index]}\\\": {feature_descriptions[feature2_base]} (y-axis).\\n\\n\"\n",
    "    \"The yellow points ð¢ represent \\\"benign tumors\\\", and the purple points ð´ represent \\\"malignant tumors\\\".\\n\"\n",
    "    \"The red dashed line represents the decision boundary determined by the logistic regression model.\\n\\n\" # explain what a decision boundary is better\n",
    "    \"Each run of this script might result in different features being selected, hence different visualizations and boundaries.\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Circling back to the real-world application of our work, this model has the potential to save lives. By using past data to train the model, we can now quickly and accurately classify new patients as having benign or malignant tumors based on their data. This means that if a new patient's data falls on one side of the decision boundary, with the accuracy of the model in mind, we can quickly determine their diagnosis and take appropriate action. This ability to rapidly and accurately diagnose breast cancer can lead to earlier interventions, better treatment plans, and ultimately, improved patient outcomes.\n",
    "\n",
    "run the cell below many times..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how it will look like in real life...\n",
    "\n",
    "# Randomly select two features to visualize\n",
    "feature_indices = random.sample(range(X.shape[1]), 2)\n",
    "feature1_index = feature_indices[0]\n",
    "feature2_index = feature_indices[1]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train[:, feature_indices], y_train)  # Fit model only on selected features\n",
    "\n",
    "# Predict on the test set using the same features\n",
    "y_pred = model.predict(X_test[:, feature_indices])\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Line Plot Coordinates\n",
    "x_values = np.linspace(X_test[:, feature1_index].min(), X_test[:, feature1_index].max(), 100)\n",
    "y_values = -(model.intercept_ + model.coef_[0][0] * x_values) / model.coef_[0][1]\n",
    "\n",
    "# Defining benign data and malignant data\n",
    "benign_data = [X_test[y_test == 0][:, feature1_index], X_test[y_test == 0][:, feature2_index], breast_cancer.target_names[0]]\n",
    "malignant_data = [X_test[y_test == 1][:, feature1_index], X_test[y_test == 1][:, feature2_index], breast_cancer.target_names[1]]\n",
    "\n",
    "# Plotting the data points and the decision boundary using scatter_plot\n",
    "scatter_plot(\n",
    "    X={'data': [benign_data[0], benign_data[1]], 'color': 'blue', 'label': breast_cancer.target_names[0]}, \n",
    "    y={'data': [malignant_data[0], malignant_data[1]], 'color': 'blue', 'label': breast_cancer.target_names[1]}, \n",
    "    line_plot={'x': x_values, 'y': y_values, 'color': 'blue', 'linestyle': '--', 'fill_colors': ['green', 'red'], 'model': model},\n",
    "    title=f'{breast_cancer.feature_names[feature2_index]} vs {breast_cancer.feature_names[feature1_index]}', \n",
    "    show_legend=False,\n",
    "    xlabel=breast_cancer.feature_names[feature1_index],\n",
    "    ylabel=breast_cancer.feature_names[feature2_index]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Regression is a method for modeling the relationship between a dependent variable and one or more independent variables. By leveraging past data, regression helps us find patterns and make predictions about future outcomes.\n",
    "\n",
    "With the power of programming, regression becomes an even more potent tool in the hands of data scientists. It allows us to automate the analysis of large datasets, quickly build models, and visualize complex relationships. This enables us to gain insights and make data-driven decisions more efficiently.\n",
    "\n",
    "However, there is always room for improvement. While our current model uses a simple logistic regression approach, we can explore more advanced techniques. For instance, we can use polynomial regression to fit curves rather than straight lines, or employ regularization methods to enhance model performance, you don't need to know what these methods are now, but they open doors for future exploration. Additionally, there are many ways to refine the models we've created, such as incorporating more variables, and using cross-validation to ensure robustness.\n",
    "\n",
    "As we continue to learn and apply these advanced techniques, we can build more accurate and reliable models, ultimately leading to better predictions and more informed decisions in various fields, including healthcare, finance, and beyond.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
