{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c996be64-7528-4de5-9122-42153aa87bae",
   "metadata": {},
   "source": [
    "## DSI-06 Homework 4: ANSWERS\n",
    "From Chapter 5, found on pages 225-226 of ISLP\n",
    "\n",
    "*In Chapter 4, we used logistic regression to predict the probability of default using income and balance on the `Default` data set. We will now estimate the test error of this logistic regression model using the validation set approach. Do not forget to set a random seed before beginning your analysis.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9c640b-16c4-4022-91c3-d5fa56c2d238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import subplots\n",
    "import statsmodels.api as sm\n",
    "import random\n",
    "\n",
    "# Import specific objects\n",
    "from ISLP import load_data\n",
    "from ISLP import confusion_table\n",
    "from ISLP.models import contrast\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "                         summarize)\n",
    "from sklearn.discriminant_analysis import \\\n",
    "     (LinearDiscriminantAnalysis as LDA,\n",
    "      QuadraticDiscriminantAnalysis as QDA)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load Default data\n",
    "Default = load_data('Default')\n",
    "Default"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4984ae5-070c-4e15-b54d-8a4371675a13",
   "metadata": {},
   "source": [
    "(a) Fit a logistic regression model that uses income and balance to predict default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7a50f6-9929-467f-a0b6-a182c24e6d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'default' to numeric (1 or 0)\n",
    "Default['default_numeric'] = Default['default'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Set random seed (use any number you wish)\n",
    "random_seed = 16 \n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "# Fit logistic regression model\n",
    "formula = 'default_numeric ~ income + balance'\n",
    "glm_model = sm.Logit.from_formula(formula, data=Default)\n",
    "glm_fit = glm_model.fit()\n",
    "\n",
    "# Print summary\n",
    "print(glm_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492555e2-7bd0-4366-b5ff-edc6a47852a2",
   "metadata": {},
   "source": [
    "The standard errors of the coefficients are listed in the table above as std err (Income -> 4.99e-06, Balance\n",
    "-> 0.000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a66e054-7216-4c84-8fd0-92f071df208b",
   "metadata": {},
   "source": [
    "Using the validation set approach, estimate the test error of this model. In order to do this, you must perform the following steps:\n",
    "\n",
    "(i) Split the sample set into a training set and a validation set.\n",
    "\n",
    "(ii)  Fit a multiple logistic regression model using only the training observations.\n",
    "\n",
    "(iii)  Obtain a prediction of default status for each individual in the validation set by computing the posterior probability of default for that individual, and classifying the individual to the default category if the posterior probability is greater than 0.5.\n",
    "\n",
    "(vi)  Compute the validation set error, which is the fraction of the observations in the validation set that are misclassified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a074d995-6701-49b5-8ad3-7e9a624315bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step (i): Split the dataset into training and validation sets\n",
    "train_df, valid_df = train_test_split(Default, test_size=0.2, random_state=16)\n",
    "\n",
    "# Step (ii): Fit a logistic regression model using only the training observations\n",
    "X_train = train_df[['income', 'balance']]\n",
    "y_train = train_df['default']\n",
    "logreg_model = LogisticRegression()\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# Step (iii): Obtain predictions on the validation set\n",
    "X_valid = valid_df[['income', 'balance']]\n",
    "y_valid_pred_prob = logreg_model.predict_proba(X_valid)[:, 1]\n",
    "y_valid_pred = np.where(y_valid_pred_prob > 0.5, 'Yes', 'No')  # Convert to string labels\n",
    "\n",
    "# Step (iv): Compute the validation set error\n",
    "validation_error = 1 - accuracy_score(valid_df['default'], y_valid_pred)\n",
    "\n",
    "# Display the validation set error\n",
    "print(f\"Validation Set Error: {validation_error:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53bb8fc-402b-4e58-8819-1d9256da152a",
   "metadata": {},
   "source": [
    "(c)Â  Repeat the process in (b) three times, using three different splits of the observations into a training set and a validation set. Comment on the results obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e883b7-f332-41c6-b61d-2655a695f327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of repetitions\n",
    "num_repeats = 3\n",
    "\n",
    "for repeat in range(num_repeats):\n",
    "    # Step (i): Split the dataset into training and validation sets\n",
    "    train_df, valid_df = train_test_split(Default, test_size=0.2, random_state=16 * (repeat + 1))\n",
    "\n",
    "    # Step (ii): Fit a logistic regression model using only the training observations\n",
    "    X_train = train_df[['income', 'balance']]\n",
    "    y_train = train_df['default']\n",
    "    logreg_model = LogisticRegression()\n",
    "    logreg_model.fit(X_train, y_train)\n",
    "\n",
    "    # Step (iii): Obtain predictions on the validation set\n",
    "    X_valid = valid_df[['income', 'balance']]\n",
    "    y_valid_pred_prob = logreg_model.predict_proba(X_valid)[:, 1]\n",
    "    y_valid_pred = np.where(y_valid_pred_prob > 0.5, 'Yes', 'No')  # Convert to string labels\n",
    "\n",
    "    # Step (iv): Compute the validation set error\n",
    "    validation_error = 1 - accuracy_score(valid_df['default'], y_valid_pred)\n",
    "\n",
    "    # Display the validation set error for each iteration\n",
    "    print(f\"Validation Set Error (Repeat {repeat + 1}): {validation_error:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054c300b-65d1-4409-bb28-bc4fbcca7cb4",
   "metadata": {},
   "source": [
    "(d) Now consider a logistic regression model that predicts the probability of default using income, balance, and a dummy variable for student. Estimate the test error for this model using the validation set approach. Comment on whether or not including a dummy variable for student leads to a reduction in the test error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb329eb-838a-4bd9-a97a-5402a03c7c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of repetitions\n",
    "num_repeats = 3\n",
    "\n",
    "for repeat in range(num_repeats):\n",
    "    # Step (i): Split the dataset into training and validation sets\n",
    "    train_df, valid_df = train_test_split(Default, test_size=0.2, random_state=16 * (repeat + 1))\n",
    "\n",
    "    # Step (ii): Define a pipeline for preprocessing and logistic regression\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', 'passthrough', ['income', 'balance']),\n",
    "            ('cat', OneHotEncoder(), ['student'])\n",
    "        ])\n",
    "\n",
    "    model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                            ('classifier', LogisticRegression())])\n",
    "\n",
    "    # Step (iii): Fit the logistic regression model using only the training observations\n",
    "    X_train = train_df[['income', 'balance', 'student']]\n",
    "    y_train = train_df['default']\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Step (iv): Obtain predictions on the validation set\n",
    "    X_valid = valid_df[['income', 'balance', 'student']]\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "\n",
    "    # Step (v): Compute the validation set error\n",
    "    validation_error = 1 - accuracy_score(valid_df['default'], y_valid_pred)\n",
    "\n",
    "    # Display the validation set error for each iteration\n",
    "    print(f\"Validation Set Error (Repeat {repeat + 1}): {validation_error:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
