{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dde65af3-543e-49db-9cdd-23c58593e30c",
   "metadata": {},
   "source": [
    "## DSI-06 Homework 1: ANSWERS\n",
    "From Chapter 3, found on page 129 of ISLP\n",
    "\n",
    "*This question involves the use of simple linear regression on the Auto data set*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb70b75-4f4d-4081-86f3-7c48600e1023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Import specific objects\n",
    "from textwrap import wrap # to avoiding label overlapping in plots\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "                         summarize,\n",
    "                         poly)\n",
    "\n",
    "# Load dataset\n",
    "Auto = load_data('Auto')\n",
    "Auto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68acc068-630e-42e4-bcf6-e388732c67f2",
   "metadata": {},
   "source": [
    "_a)_\tUse the `sm.OLS()` function to perform a simple linear regression with `mpg` as the response and `horsepower` as the predictor. Use the `summarize()` function to print the results. Comment on the output\n",
    "\n",
    "(i) Is there a relationship between the predictor and the response?\n",
    "\n",
    "*Yes, there is a relationship between the predictor and the response. We can reject the null hypothesis that the regression coefficients are zero, since the F-statistic is much larger than 1 and the p-value is zero.*\n",
    "\n",
    "(ii) How strong is the relationship between the predictor and the response?\n",
    "\n",
    "*Since the R-squared value is 0.606, we can say that approximately 60% of the variance in mpg is explained by horsepower.*\n",
    "\n",
    "(iii) Is the relationship between the predictor and the response positive or negative?\n",
    "\n",
    "*The relationship is negative because the coefficient corresponding to horsepower is equal to -0.1578.*\n",
    "\n",
    "\n",
    "(iv) What is the predicted mpg associated with a horsepower of 98? What are the associated 95 % confidence and prediction intervals?\n",
    "\n",
    "*The predicted 'mpg' is equal to 24.47, with a 95% confidence interval of (-0.17, -0.15) and a 95% prediction interval of (23.97, 24.96).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f3b7b9-92e4-40ac-980b-19bbc0300660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a constant term to the predictor variable\n",
    "X = sm.add_constant(Auto['horsepower'])\n",
    "y = Auto['mpg']\n",
    "\n",
    "# Fit the OLS model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9ae6b0-705b-4146-bf5d-ae39a7c89d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize results\n",
    "summarize(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d9eb14-f19c-4515-abe5-53005c7ba264",
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = 39.9359\n",
    "slope = -0.1578\n",
    "horsepower_value = 98\n",
    "\n",
    "# Calculate predicted MPG\n",
    "predicted_mpg = intercept + (slope * horsepower_value)\n",
    "print(f\"Predicted MPG: {predicted_mpg:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8830f551-9b16-43c3-b4ea-02fcbe8034bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get confidence and prediction intervals\n",
    "conf_interval = model.conf_int(alpha=0.05)\n",
    "predict_interval = model.get_prediction(exog=[1, 98]).conf_int(alpha=0.05)\n",
    "\n",
    "# Extract values from NumPy arrays\n",
    "conf_interval_values = tuple(conf_interval.loc['horsepower'].values)\n",
    "predict_interval_values = tuple(predict_interval[0])\n",
    "\n",
    "print(f\"95% Confidence Interval: {conf_interval_values}\")\n",
    "print(f\"95% Prediction Interval: {predict_interval_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8e20e6-d15b-4c34-9cbe-650d582df4ab",
   "metadata": {},
   "source": [
    "_b)_\tPlot the response and the predictor in a new set of axes `ax`. Use the `ax.axline()` method or the `abline()` function defined in the lab to display the least squares regression line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dcb043-639a-450e-a9bc-ea85d7dfacc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the response and predictor\n",
    "fig, ax = subplots()\n",
    "ax.scatter(Auto['horsepower'], Auto['mpg'], alpha=0.7, label='Data points')\n",
    "ax.set_xlabel('Horsepower')\n",
    "ax.set_ylabel('MPG')\n",
    "\n",
    "# Adding the regression line\n",
    "ax.plot(Auto['horsepower'], model.predict(X), color='red', label='Regression Line')\n",
    "ax.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4acb0fa-4fbb-4164-a81d-2f3d20237e7f",
   "metadata": {},
   "source": [
    "_c)_\tProduce some of diagnostic plots of the least squares regression fit as described in the lab. Comment on any problems you see with the fit.\n",
    "\n",
    "- The QQ plot indicates that the assumption of normality does hold, since we can fit a straight line quite well.\n",
    "- For the Scale-Location plot, the residuals are plotted against the fitted values, but here they are all made positive and normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b20459-e8e8-43ca-b5d6-88202a008cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic plots\n",
    "fig, ax = subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "# Residuals vs Fitted Values\n",
    "ax[0, 0].scatter(model.fittedvalues, model.resid, alpha=0.7)\n",
    "ax[0, 0].set_xlabel('Fitted Values')\n",
    "ax[0, 0].set_ylabel('Residuals')\n",
    "ax[0, 0].set_title('Residuals vs Fitted Values')\n",
    "\n",
    "# QQ Plot\n",
    "sm.qqplot(model.resid, line='s', ax=ax[0, 1])\n",
    "ax[0, 1].set_title('QQ Plot')\n",
    "\n",
    "# Scale-Location plot\n",
    "ax[1, 0].scatter(model.fittedvalues, abs(model.get_influence().resid_studentized_internal), alpha=0.7)\n",
    "ax[1, 0].set_xlabel('Fitted Values')\n",
    "ax[1, 0].set_ylabel('Square Root of Standardized Residuals')\n",
    "ax[1, 0].set_title('Scale-Location Plot')\n",
    "\n",
    "# Leverage-Residual Squared plot\n",
    "sm.graphics.influence_plot(model, ax=ax[1, 1], criterion=\"cooks\", text_coords=(0.1, 0.1))\n",
    "ax[1, 1].set_title('Leverage-Residual Squared Plot')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
