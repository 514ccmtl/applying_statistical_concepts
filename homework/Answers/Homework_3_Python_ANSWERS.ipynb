{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e5f602d-0241-4f0e-9aaa-aedc110ae8d0",
   "metadata": {},
   "source": [
    "## DSI-06 Homework 3: ANSWERS\n",
    "From Chapter 4, found on pages 196-197 of ISLP\n",
    "\n",
    "*This question should be answered using the `Weekly` data set, which is part of the ISLP package. This data is similar in nature to the Smarket data from this section's in-class exercises, except that it contains 1, 089 weekly returns for 21 years, from the beginning of 1990 to the end of 2010.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af43c39d-5b12-4cd9-82a9-facb32c835de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import subplots\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Import specific objects\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "                         summarize)\n",
    "from ISLP import load_data\n",
    "from ISLP import confusion_table\n",
    "from ISLP.models import contrast\n",
    "from sklearn.discriminant_analysis import \\\n",
    "     (LinearDiscriminantAnalysis as LDA,\n",
    "      QuadraticDiscriminantAnalysis as QDA)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load dataset\n",
    "Weekly = load_data('Weekly')\n",
    "Weekly"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c5ccd47-ca85-4e62-b0e1-0b429f2730a8",
   "metadata": {},
   "source": [
    "a) Produce some numerical and graphical summaries of the `Weekly` data. Do there appear to be any patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9f5185-9cb5-4da8-a51a-02a41f5048c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the describe() function to obtain basic summary statistics for each variable \n",
    "print(Weekly.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60996142-431b-489d-a770-cdb9ab1b377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = Weekly.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "cor_Weekly = numeric_columns.corr()\n",
    "\n",
    "# Plot the correlation matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cor_Weekly, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f2f65e-2648-4703-9ca1-92ed3ee20fac",
   "metadata": {},
   "source": [
    "We can see a pattern! We have a significant linear relationship between Year and Volume. The correlational plot does not seem to illustrate that any other variables are significantly linearly related."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86001139-f7c5-43d9-b10a-93a59e810cd4",
   "metadata": {},
   "source": [
    "b) Use the full data set to perform a logistic regression with Direction as the response and the five lag variables plus Volume as predictors. Use the summary function to print the results. Do any of the predictors appear to be statistically significant? If so, which ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e034864-89b7-4854-a5a3-87d8450515bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag variables\n",
    "for i in range(1, 6):\n",
    "    Weekly[f'Lag_{i}'] = Weekly['Direction'].shift(i)\n",
    "\n",
    "# Drop rows with missing values due to lag creation\n",
    "Weekly = Weekly.dropna()\n",
    "\n",
    "# Select predictors and response variable\n",
    "allvars = Weekly.columns.drop(['Today', 'Direction', 'Year'])\n",
    "design = sm.add_constant(pd.get_dummies(Weekly[allvars], drop_first=True))\n",
    "X = design\n",
    "y = (Weekly['Direction'] == 'Up').astype(int)\n",
    "\n",
    "# Fit logistic regression model\n",
    "glm = sm.GLM(y, X, family=sm.families.Binomial())\n",
    "results = glm.fit()\n",
    "\n",
    "# Print the summary of the logistic regression\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3a9e34-154d-4325-98b1-84dc18464b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cf6307-348a-4f34-904e-40638999a9fc",
   "metadata": {},
   "source": [
    "The column labelled Pr(>|z|) gives the p-values associated with each variables. Recall that the p-values\n",
    "indicate whether or not to reject the null hypothesis that there is no association between the response and\n",
    "predictor variable. Lag 2 appear to be statistically significant!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dcf794-503d-4ffd-8501-3b2b9afa9a3e",
   "metadata": {},
   "source": [
    "c) Compute the confusion matrix and overall fraction of correct predictions. Explain what the confusion matrix is telling you about the types of mistakes made by logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fae233-67a4-4b81-ad9e-63efd6fbf582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities\n",
    "y_prob = results.predict()\n",
    "\n",
    "# Convert probabilities to binary predictions (0 or 1)\n",
    "y_pred = (y_prob > 0.5).astype(int)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "\n",
    "# Extract values from the confusion matrix\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Compute overall fraction of correct predictions (accuracy)\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "\n",
    "# Print confusion matrix and accuracy\n",
    "print(\"Confusion Matrix:\")\n",
    "print(pd.DataFrame(cm, columns=['Predicted 0', 'Predicted 1'], index=['Actual 0', 'Actual 1']))\n",
    "print(\"\\nOverall Fraction of Correct Predictions (Accuracy):\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663e9220-055f-4135-80c4-f288f65e8978",
   "metadata": {},
   "source": [
    "d) Now fit the logistic regression model using a training data period from 1990 to 2008, with Lag2 as the only predictor. Compute the confusion matrix and the overall fraction of correct predictions for the held out data (that is, the data from 2009 and 2010)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aed944-4885-45ec-8f14-2725ccc2455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for the training period (1990 to 2008)\n",
    "train_data = Weekly[(Weekly['Year'] >= 1990) & (Weekly['Year'] <= 2008)]\n",
    "\n",
    "# Filter data for the test period (2009 and 2010)\n",
    "test_data = Weekly[(Weekly['Year'] == 2009) | (Weekly['Year'] == 2010)]\n",
    "\n",
    "# Extract predictors and response variables for training\n",
    "X_train = train_data[['Lag2']]\n",
    "y_train = train_data['Direction']\n",
    "\n",
    "# Extract predictors and response variables for testing\n",
    "X_test = test_data[['Lag2']]\n",
    "y_test = test_data['Direction']\n",
    "\n",
    "# Fit logistic regression model on the training data\n",
    "logreg_model = LogisticRegression()\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# Get predicted probabilities on the test data\n",
    "y_prob = logreg_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Convert probabilities to binary predictions (0 or 1)\n",
    "y_pred = (y_prob > 0.5).astype(int)\n",
    "\n",
    "# Convert labels in y_true to numeric values (0 and 1)\n",
    "y_true_numeric = y_test.map({'Down': 0, 'Up': 1})\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true_numeric, y_pred)\n",
    "\n",
    "# Extract values from the confusion matrix\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Compute overall fraction of correct predictions (accuracy)\n",
    "accuracy = accuracy_score(y_true_numeric, y_pred)\n",
    "\n",
    "# Print confusion matrix and accuracy\n",
    "print(\"Confusion Matrix:\")\n",
    "print(pd.DataFrame(cm, columns=['Predicted Down', 'Predicted Up'], index=['Actual Down', 'Actual Up']))\n",
    "print(\"\\nOverall Fraction of Correct Predictions (Accuracy):\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e216ddf1-fe11-4828-91cd-602dcc99f110",
   "metadata": {},
   "source": [
    "e) Repeat (d) using LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f61bb3-e580-44d8-bdf2-fd1df2956720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for the training period (1990 to 2008)\n",
    "train_data = Weekly[(Weekly['Year'] >= 1990) & (Weekly['Year'] <= 2008)]\n",
    "\n",
    "# Filter data for the test period (2009 and 2010)\n",
    "test_data = Weekly[(Weekly['Year'] == 2009) | (Weekly['Year'] == 2010)]\n",
    "\n",
    "# Extract predictors and response variables for training\n",
    "X_train = train_data[['Lag2']]\n",
    "y_train = train_data['Direction']\n",
    "\n",
    "# Extract predictors and response variables for testing\n",
    "X_test = test_data[['Lag2']]\n",
    "y_test = test_data['Direction']\n",
    "\n",
    "# Fit LDA model on the training data\n",
    "lda_model = LDA()\n",
    "lda_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the test data\n",
    "y_pred = lda_model.predict(X_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Extract values from the confusion matrix\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Compute overall fraction of correct predictions (accuracy)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print confusion matrix and accuracy\n",
    "print(\"Confusion Matrix:\")\n",
    "print(pd.DataFrame(cm, columns=['Predicted Down', 'Predicted Up'], index=['Actual Down', 'Actual Up']))\n",
    "print(\"\\nOverall Fraction of Correct Predictions (Accuracy):\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b1aae8-9bd0-4d41-8bed-863ff0a2117f",
   "metadata": {},
   "source": [
    "f) Repeat (d) using QDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf6063f-c52e-4eba-a930-8aaa4ed80c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for the training period (1990 to 2008)\n",
    "train_data = Weekly[(Weekly['Year'] >= 1990) & (Weekly['Year'] <= 2008)]\n",
    "\n",
    "# Filter data for the test period (2009 and 2010)\n",
    "test_data = Weekly[(Weekly['Year'] == 2009) | (Weekly['Year'] == 2010)]\n",
    "\n",
    "# Extract predictors and response variables for training\n",
    "X_train = train_data[['Lag2']]\n",
    "y_train = train_data['Direction']\n",
    "\n",
    "# Extract predictors and response variables for testing\n",
    "X_test = test_data[['Lag2']]\n",
    "y_test = test_data['Direction']\n",
    "\n",
    "# Fit QDA model on the training data\n",
    "qda_model = QDA()\n",
    "qda_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the test data\n",
    "y_pred = qda_model.predict(X_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Extract values from the confusion matrix\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Compute overall fraction of correct predictions (accuracy)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print confusion matrix and accuracy\n",
    "print(\"Confusion Matrix:\")\n",
    "print(pd.DataFrame(cm, columns=['Predicted Down', 'Predicted Up'], index=['Actual Down', 'Actual Up']))\n",
    "print(\"\\nOverall Fraction of Correct Predictions (Accuracy):\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd84667-3df1-4f84-b2c6-c8ded360c91b",
   "metadata": {},
   "source": [
    "g) Repeat (d) using KNN with K = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abebebc-4052-4d28-a1cd-1e9c69011d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for the training period (1990 to 2008)\n",
    "train_data = Weekly[(Weekly['Year'] >= 1990) & (Weekly['Year'] <= 2008)]\n",
    "\n",
    "# Filter data for the test period (2009 and 2010)\n",
    "test_data = Weekly[(Weekly['Year'] == 2009) | (Weekly['Year'] == 2010)]\n",
    "\n",
    "# Extract predictors and response variables for training\n",
    "X_train = train_data[['Lag2']]\n",
    "y_train = train_data['Direction']\n",
    "\n",
    "# Extract predictors and response variables for testing\n",
    "X_test = test_data[['Lag2']]\n",
    "y_test = test_data['Direction']\n",
    "\n",
    "# Fit KNN model on the training data with K=1\n",
    "knn_model = KNeighborsClassifier(n_neighbors=1)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the test data\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Extract values from the confusion matrix\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Compute overall fraction of correct predictions (accuracy)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print confusion matrix and accuracy\n",
    "print(\"Confusion Matrix:\")\n",
    "print(pd.DataFrame(cm, columns=['Predicted Down', 'Predicted Up'], index=['Actual Down', 'Actual Up']))\n",
    "print(\"\\nOverall Fraction of Correct Predictions (Accuracy):\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d27d831-0188-4381-8deb-218ec062d4f1",
   "metadata": {},
   "source": [
    "h) Repeat (d) using naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c27b5f-8296-4b07-b67d-6482ca851cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for the training period (1990 to 2008)\n",
    "train_data = Weekly[(Weekly['Year'] >= 1990) & (Weekly['Year'] <= 2008)]\n",
    "\n",
    "# Filter data for the test period (2009 and 2010)\n",
    "test_data = Weekly[(Weekly['Year'] == 2009) | (Weekly['Year'] == 2010)]\n",
    "\n",
    "# Extract predictors and response variables for training\n",
    "X_train = train_data[['Lag2']]\n",
    "y_train = train_data['Direction']\n",
    "\n",
    "# Extract predictors and response variables for testing\n",
    "X_test = test_data[['Lag2']]\n",
    "y_test = test_data['Direction']\n",
    "\n",
    "# Fit Naive Bayes model on the training data\n",
    "naive_bayes_model = GaussianNB()\n",
    "naive_bayes_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the test data\n",
    "y_pred = naive_bayes_model.predict(X_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Extract values from the confusion matrix\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Compute overall fraction of correct predictions (accuracy)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print confusion matrix and accuracy\n",
    "print(\"Confusion Matrix:\")\n",
    "print(pd.DataFrame(cm, columns=['Predicted Down', 'Predicted Up'], index=['Actual Down', 'Actual Up']))\n",
    "print(\"\\nOverall Fraction of Correct Predictions (Accuracy):\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2fdba9-6143-41c7-a3f6-d147170192f9",
   "metadata": {},
   "source": [
    "i) Which of these methods appears to provide the best results on this data?\n",
    "\n",
    "*Given the accuracy and test error rate, the Linear Discriminant Analysis, Quadratic Discriminant Analysis, and logistic regression model performed the best (accuracy of 62.5%, test error of 37.5%).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300ceabd-ddaf-4779-b6f9-cb604c24fe10",
   "metadata": {},
   "source": [
    "j) Experiment with different combinations of predictors, including possible transformations and interactions, for each of the methods. Report the variables, method, and associated confusion matrix that appears to provide the best results on the held out data. Note that you should also experiment with values for K in the KNN classifier.\n",
    "\n",
    "Examples: Logistic regression with interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f35da6-2f96-448b-8aa1-8f5607c25e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Direction' to numeric format\n",
    "label_encoder = LabelEncoder()\n",
    "Weekly['Direction_numeric'] = label_encoder.fit_transform(Weekly['Direction'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(Weekly, test_size=0.2, random_state=16)\n",
    "\n",
    "# Fit logistic regression model with interaction term on the training data\n",
    "formula = 'Direction_numeric ~ Lag2 * Lag4'\n",
    "log_fit_interaction = sm.Logit.from_formula(formula, data=train_data).fit()\n",
    "\n",
    "# Predict probabilities on the test data\n",
    "log_probs_interaction = log_fit_interaction.predict(test_data)\n",
    "\n",
    "# Convert probabilities to binary predictions (0 or 1)\n",
    "log_pred = (log_probs_interaction > 0.5).astype(int)\n",
    "\n",
    "# Decode numeric predictions back to original labels\n",
    "log_pred_labels = label_encoder.inverse_transform(log_pred)\n",
    "\n",
    "# Create a confusion matrix\n",
    "cm = confusion_matrix(test_data['Direction'], log_pred_labels)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(pd.DataFrame(cm, columns=['Predicted Down', 'Predicted Up'], index=['Actual Down', 'Actual Up']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597d3593-285a-4c67-82c6-02370ee4cc8a",
   "metadata": {},
   "source": [
    "Example: KNN, $K = 10$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f065a84e-99bb-4604-87ed-5574745544af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for the training period (1990 to 2008)\n",
    "train_data = Weekly[(Weekly['Year'] >= 1990) & (Weekly['Year'] <= 2008)]\n",
    "\n",
    "# Filter data for the test period (2009 and 2010)\n",
    "test_data = Weekly[(Weekly['Year'] == 2009) | (Weekly['Year'] == 2010)]\n",
    "\n",
    "# Extract predictors and response variables for training\n",
    "X_train = train_data[['Lag2']]\n",
    "y_train = train_data['Direction']\n",
    "\n",
    "# Extract predictors and response variables for testing\n",
    "X_test = test_data[['Lag2']]\n",
    "y_test = test_data['Direction']\n",
    "\n",
    "# Fit KNN model on the training data with K=1\n",
    "knn_model = KNeighborsClassifier(n_neighbors=10)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the test data\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Extract values from the confusion matrix\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Compute overall fraction of correct predictions (accuracy)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print confusion matrix and accuracy\n",
    "print(\"Confusion Matrix:\")\n",
    "print(pd.DataFrame(cm, columns=['Predicted Down', 'Predicted Up'], index=['Actual Down', 'Actual Up']))\n",
    "print(\"\\nOverall Fraction of Correct Predictions (Accuracy):\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
