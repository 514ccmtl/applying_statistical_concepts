% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  ignorenonframetext,
  aspectratio=169,
]{beamer}
\usepackage{pgfpages}
\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption label separator}{: }
\setbeamercolor{caption name}{fg=normal text.fg}
\beamertemplatenavigationsymbolsempty
% Prevent slide breaks in the middle of a paragraph
\widowpenalties 1 10000
\raggedbottom
\setbeamertemplate{part page}{
  \centering
  \begin{beamercolorbox}[sep=16pt,center]{part title}
    \usebeamerfont{part title}\insertpart\par
  \end{beamercolorbox}
}
\setbeamertemplate{section page}{
  \centering
  \begin{beamercolorbox}[sep=12pt,center]{part title}
    \usebeamerfont{section title}\insertsection\par
  \end{beamercolorbox}
}
\setbeamertemplate{subsection page}{
  \centering
  \begin{beamercolorbox}[sep=8pt,center]{part title}
    \usebeamerfont{subsection title}\insertsubsection\par
  \end{beamercolorbox}
}
\AtBeginPart{
  \frame{\partpage}
}
\AtBeginSection{
  \ifbibliography
  \else
    \frame{\sectionpage}
  \fi
}
\AtBeginSubsection{
  \frame{\subsectionpage}
}

\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usetheme[]{Madrid}
\usecolortheme{DarkBlue}
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\newif\ifbibliography
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
\usepackage{caption}
% Make caption package work with longtable
\makeatletter
\def\fnum@table{\tablename~\thetable}
\makeatother
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\definecolor{DarkBlue}{rgb}{0.05, 0.15, 0.3}
\setbeamercolor{structure}{fg=DarkBlue}
\makeatletter
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[many]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={6.4: Resampling Methods},
  pdfauthor={Navona Calarco},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{6.4: Resampling Methods}
\author{Navona Calarco}
\date{}
\institute{The University of Toronto}

\begin{document}
\frame{\titlepage}
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[boxrule=0pt, frame hidden, enhanced, interior hidden, sharp corners, breakable, borderline west={3pt}{0pt}{shadecolor}]}{\end{tcolorbox}}\fi

\begin{frame}{Introduction}
\protect\hypertarget{introduction}{}
Resampling methods work by first drawing a sample from the training data
set and then fitting the statistical model of interest on this subset of
the data. This process is repeated many times which allows us to gain
more information about a model without requiring more data.

This section will cover two resampling methods:

\begin{itemize}
\item
  Cross-validation
\item
  The bootstrap
\end{itemize}
\end{frame}

\begin{frame}{The Validation Set Approach}
\protect\hypertarget{the-validation-set-approach}{}
The \textbf{validation set approach} estimates the test error associated
with fitting a statistical model to a set of observations.

\begin{itemize}
\item
  Randomly divide the set of observations into a \alert{training set}
  and a \alert{validation set}.
\item
  Fit the model on the training set.
\item
  Predict responses on the validation set.
\item
  The error rate of the validation set gives an estimate of the test
  error rate.
\end{itemize}

Finding the error rate of the validation set depends on the statistical
model.

\begin{itemize}
\item
  In the regression setting mean squared error (MSE) is usually used.
\item
  In the classification setting, the number of misclassified
  observations is used.
\end{itemize}
\end{frame}

\begin{frame}{The Validation Set Approach}
\protect\hypertarget{the-validation-set-approach-1}{}
There are two potential drawback to this approach:

\begin{itemize}
\item
  The \alert{validation set error rate can be highly variable} since it
  depends on which observations are included in the training set versus
  the validation set.
\item
  The validation set error rate may
  \alert{overestimate the test error rate} since the model is being fit
  on a smaller training set.
\end{itemize}

Cross-validation is an extension of the validation set approach that
accounts for these issues.
\end{frame}

\begin{frame}{Exercises: The Validation Set Approach}
\protect\hypertarget{exercises-the-validation-set-approach}{}
Open the Resampling Methods R Markdown file.

\begin{itemize}
\item
  Go over the ``Getting Started'' section together as a class.
\item
  Go over the ``The Validation Set Approach'' section together as a
  class.
\item
  5 minutes for students to complete the questions from ``The Validation
  Set Approach''.
\item
  Questions should be completed at home if time does not allow.
\end{itemize}
\end{frame}

\begin{frame}{Leave-One-Out Cross-Validation}
\protect\hypertarget{leave-one-out-cross-validation}{}
Leave-one-out cross-validation (LOOCV) follows the same steps as the
validation set approach except the
\alert{validation set is just one single observation}. Then,

\begin{itemize}
\item
  Fit model on the training data set.
\item
  Make prediction for the response of the one validation observation
  using the fitted model.
\item
  Compute the validation set error.
\item
  Repeat this process for every observation.
\end{itemize}

The LOOCV estimate of the test error is the average of all \(n\) of the
validation set errors.
\end{frame}

\begin{frame}{Leave-One-Out Cross-Validation}
\protect\hypertarget{leave-one-out-cross-validation-1}{}
How is the LOOCV approach better than the validation set approach?

\begin{itemize}
\item
  It has \alert{less bias} and
  \alert{does not overestimate the test error rate} as much since it is
  using a lot more observations to train the model.
\item
  The LOOCV result will not vary since there is no randomness in the
  training and validation set splits.
\end{itemize}
\end{frame}

\begin{frame}{Exercises: Leave-One-Out Cross-Validation}
\protect\hypertarget{exercises-leave-one-out-cross-validation}{}
Open the Resampling Methods R Markdown file.

\begin{itemize}
\item
  Go over the ``Leave-One-Out Cross-Validation'' section together as a
  class.
\item
  10 minutes for students to complete the questions from ``Leave-One-Out
  Cross-Validation''.
\item
  Questions should be completed at home if time does not allow.
\end{itemize}
\end{frame}

\begin{frame}{\(k\)-Fold Cross-Validation}
\protect\hypertarget{k-fold-cross-validation}{}
\(k\)-fold cross validation involves randomly dividing the set of
observations into \(k\) approximately equally sized groups. Then,

\begin{itemize}
\item
  Fit the model using the observations from all but one of the groups.
\item
  Make predictions for the response of the observations in the remaining
  group.
\item
  Compute the validation set error.
\item
  Repeat this process for each group.
\end{itemize}

The \(k\)-fold cross validation estimate of the test error is the
average of the \(k\) validation set errors.

LOOCV is a special case of the \(k\)-fold cross validation approach
using \(k = n\) (\$n = \$ number of observations).
\end{frame}

\begin{frame}{Comparing LOOC and \(k\)-fold CV}
\protect\hypertarget{comparing-looc-and-k-fold-cv}{}
\begin{itemize}
\item
  The
  \alert{computational time/effort for $k$-fold CV for $k < n$ is less}
  since we are fitting fewer models in the process.
\item
  \alert{LOOCV is less biased} in its estimation of the test error rate
  since it trains the model on more observations.
\end{itemize}

-\alert{LOOCV has a test error estimate that has higher variance} than
\(k\)-fold CV (\(k < n\))

\begin{itemize}
\item
  the models in the LOOCV process are fit with nearly identical training
  sets
\item
  thus, each test error result is much more correlated with one another
  than they would be for \(k\)-fold CV
\item
  averaging highly correlated quantities has a higher variance than if
  they were not correlated
\end{itemize}

Thus, there is a bias-variance trade-off when it comes to choosing \(k\)
for \(k\)-fold cross-validation. Typically \(k = 5\) or \(k = 10\) is
used.
\end{frame}

\begin{frame}{Exercises: \(k\)-fold CV}
\protect\hypertarget{exercises-k-fold-cv}{}
Open the Resampling Methods R Markdown file.

\begin{itemize}
\item
  Go over the ``\(k\)-fold CV'' section together as a class.
\item
  5 minutes for students to complete the questions from ``\(k\)-fold
  CV''.
\item
  Questions should be completed at home if time does not allow.
\end{itemize}
\end{frame}

\begin{frame}{The Bootstrap}
\protect\hypertarget{the-bootstrap}{}
Suppose we wish to find the average of the population of Toronto \(\mu\)
and we have a sample of size \(n\). We can find the mean of the sample
\(\mu_s\) but this does not give any indication for how this compares to
the true population mean \(\mu\).

\alert{The bootstrap can be used to quantify the uncertainty of an estimate}
in the following way:

\begin{itemize}
\item
  Randomly sample \(n\) observations from the original sample to acquire
  a new sample of the same size (repeat observations are allowed).
\item
  Compute the desired statistic (i.e.~average age) of this new sample.
\item
  Repeat steps 1-2 many times.
\item
  Compute the standard error (SE) of the estimates.
\end{itemize}

This method is able to give us an estimate of the variability associated
with our sample mean \(\mu_s\).
\end{frame}

\begin{frame}{Exercises: The Bootstrap}
\protect\hypertarget{exercises-the-bootstrap}{}
Open the Resampling Methods R Markdown file.

\begin{itemize}
\tightlist
\item
  Go over the ``The Bootstrap'' section together as a class.
\end{itemize}
\end{frame}

\begin{frame}{References}
\protect\hypertarget{references}{}
Chapter 5 of the ISLR2 book:

James, Gareth, et al.~``Resampling Methods.'' An Introduction to
Statistical Learning: with Applications in R, 2nd ed., Springer, 2021.
\end{frame}



\end{document}
